{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motion Gesture Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:56:56.096636Z",
     "iopub.status.busy": "2021-06-07T05:56:56.096053Z",
     "iopub.status.idle": "2021-06-07T05:56:56.26807Z",
     "shell.execute_reply": "2021-06-07T05:56:56.266618Z",
     "shell.execute_reply.started": "2021-06-07T05:56:56.096495Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import gc\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No gesture',\n",
       " 'Stop Sign',\n",
       " 'Swiping Left',\n",
       " 'Swiping Right',\n",
       " 'Thumb Down',\n",
       " 'Thumb Up']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# classes label you want to use all labels \n",
    "targets_name = pd.read_csv('Labels.csv', header=None)\n",
    "targets_name.drop([0, 1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 15, 18, 21, 22, 23, 24, 25, 26], inplace=True)\n",
    "targets_name = targets_name[0].tolist()\n",
    "targets_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1844 No gesture\n",
      "1841 Thumb Up\n",
      "1821 Stop Sign\n",
      "1810 Thumb Down\n",
      "1762 Swiping Left\n",
      "1730 Swiping Right\n",
      "\n",
      "\n",
      "Total items for 6 gestures: 10808\n"
     ]
    }
   ],
   "source": [
    "# training targets\n",
    "targets = pd.read_csv('Train.csv', index_col=0).drop(columns=['frames', 'label_id', 'shape', 'format'])\n",
    "\n",
    "for key, value in targets['label'].value_counts().items():\n",
    "    if key in targets_name:\n",
    "        print(value, key)\n",
    "\n",
    "targets.sort_values('label')\n",
    "targets = targets.squeeze().to_dict()\n",
    "targets = {key:val for key, val in targets.items() if val in targets_name}\n",
    "\n",
    "print('\\n\\nTotal items for {0} gestures: {1}'.format(len(targets_name), len(targets)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259 Stop Sign\n",
      "256 No gesture\n",
      "250 Thumb Down\n",
      "247 Swiping Left\n",
      "238 Thumb Up\n",
      "231 Swiping Right\n",
      "\n",
      "\n",
      "Total items for 6 gestures: 1481\n"
     ]
    }
   ],
   "source": [
    "# validation targets\n",
    "targets_validation = pd.read_csv('Validation.csv', index_col=0).drop(columns=['frames', 'label_id', 'shape', 'format'])\n",
    "\n",
    "for key, value in targets_validation['label'].value_counts().items():\n",
    "    if key in targets_name:\n",
    "        print(value, key)\n",
    "\n",
    "targets_validation = targets_validation.squeeze().to_dict()\n",
    "targets_validation = {key:val for key, val in targets_validation.items() if val in targets_name}\n",
    "\n",
    "print('\\n\\nTotal items for {0} gestures: {1}'.format(len(targets_name), len(targets_validation)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing the frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Unify frames to be 30 in each folder.\n",
    "2. Resize the frames to 64x64 for input.\n",
    "3. Convert them to grayscale.\n",
    "4. Convert the list of frames to an np array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def release_list(a):\n",
    "    \"\"\"Function to empty the RAM.\"\"\"\n",
    "    del a[:]\n",
    "    del a\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "hm_frames = 30  # number of frames\n",
    "def get_unify_frames(path):\n",
    "    \"\"\"Unify number of frames for each training.\n",
    "    \n",
    "    Args:\n",
    "        path: path to directory.\n",
    "    \"\"\"\n",
    "    offset = 0\n",
    "\n",
    "    # pick frames\n",
    "    frames = os.listdir(path)\n",
    "    frames_count = len(frames)\n",
    "\n",
    "    if hm_frames > frames_count:\n",
    "        # duplicate last frame if video is shorter than necessary\n",
    "        frames += [frames[-1]] * (hm_frames - frames_count)\n",
    "    elif hm_frames < frames_count:\n",
    "        # if there are more frames, then sample starting offset\n",
    "        frames = frames[0:hm_frames]\n",
    "    return frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_frame(frame):\n",
    "    \"\"\"Resize frames.\n",
    "    \n",
    "    Args:\n",
    "        frame: image to be resized.\n",
    "    \"\"\"\n",
    "    frame = cv2.imread(frame)\n",
    "    frame = cv2.resize(frame, (64, 64))\n",
    "    return frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return gray image\n",
    "def rgb2gray(rgb):\n",
    "    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10808\n",
      "1481\n"
     ]
    }
   ],
   "source": [
    "# training directories\n",
    "temp = {}\n",
    "dirs = []\n",
    "for key, val in targets.items():\n",
    "    if val not in temp:\n",
    "        temp[val] = [key]\n",
    "    else:\n",
    "        temp[val].append(key)\n",
    "\n",
    "    # if len(temp[val]) <= 500:\n",
    "    dirs.append(str(key))\n",
    "\n",
    "# validation directories\n",
    "temp = {}\n",
    "dirs_cv = []\n",
    "for key, val in targets_validation.items():\n",
    "    if val not in temp:\n",
    "        temp[val] = [key]\n",
    "    else:\n",
    "        temp[val].append(key)\n",
    "\n",
    "    # if len(temp[val]) <= 62:\n",
    "    dirs_cv.append(str(key))\n",
    "\n",
    "# dirs = [str(i) for i in targets.keys()]\n",
    "# dirs_cv = [str(i) for i in targets_validation.keys()]\n",
    "\n",
    "print(len(dirs))\n",
    "print(len(dirs_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|â–Š                                                                                      | 95/10808 [00:19<36:57,  4.83it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\KAMADS~1\\AppData\\Local\\Temp/ipykernel_17816/1689183875.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframes\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mhm_frames\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# just to be sure\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mframe\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframes\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m             \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresize_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Train/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'/'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mnew_frame\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrgb2gray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_frame\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m15\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m# partition each training on two trainings.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\KAMADS~1\\AppData\\Local\\Temp/ipykernel_17816/558281806.py\u001b[0m in \u001b[0;36mresize_frame\u001b[1;34m(frame)\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mframe\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mimage\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mresized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \"\"\"\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Adjust training data\n",
    "counter_training = 0 # number of training\n",
    "training_targets = [] # training targets \n",
    "new_frames = [] # training data after resize & unify\n",
    "\n",
    "for directory in tqdm(dirs):\n",
    "    new_frame = [] # one training\n",
    "    # Frames in each folder\n",
    "    frames = get_unify_frames('Train/' + directory)\n",
    "    if len(frames) == hm_frames: # just to be sure\n",
    "        for frame in frames:\n",
    "            frame = resize_frame('Train/' + directory + '/' + frame)\n",
    "            new_frame.append(rgb2gray(frame))\n",
    "            if len(new_frame) == 15: # partition each training on two trainings.\n",
    "                new_frames.append(new_frame) # append each partition to training data\n",
    "                training_targets.append(targets_name.index(targets[int(directory)]))\n",
    "                counter_training +=1\n",
    "                new_frame = []\n",
    "                gc.collect()\n",
    "\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "with open('new-frames.pkl', 'wb') as file:\n",
    "    pickle.dump(new_frames, file)\n",
    "release_list(new_frames)\n",
    "\n",
    "with open('training-targets.pkl', 'wb') as file:\n",
    "    pickle.dump(training_targets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we do the same for the validation data\n",
    "counter_validation = 0\n",
    "cv_targets = []\n",
    "new_frames_cv = []\n",
    "\n",
    "for directory in tqdm(dirs_cv):\n",
    "    new_frame = []\n",
    "    # Frames in each folder\n",
    "    frames = get_unify_frames('Validation/' + directory)\n",
    "    if len(frames)==hm_frames:\n",
    "        for frame in frames:\n",
    "            frame = resize_frame('Validation/' + directory + '/' + frame)\n",
    "            new_frame.append(rgb2gray(frame))\n",
    "            if len(new_frame) == 15:\n",
    "                new_frames_cv.append(new_frame)\n",
    "                cv_targets.append(targets_name.index(targets_validation[int(directory)]))\n",
    "                counter_validation +=1\n",
    "                new_frame = []\n",
    "print(counter_validation)\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "with open('cv-new-frames.pkl', 'wb') as file:\n",
    "    pickle.dump(new_frames_cv, file)\n",
    "release_list(new_frames_cv)\n",
    "\n",
    "with open('cv-targets.pkl', 'wb') as file:\n",
    "    pickle.dump(cv_targets, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:57:03.263767Z",
     "iopub.status.busy": "2021-06-07T05:57:03.263335Z",
     "iopub.status.idle": "2021-06-07T05:57:03.270141Z",
     "shell.execute_reply": "2021-06-07T05:57:03.268995Z",
     "shell.execute_reply.started": "2021-06-07T05:57:03.26373Z"
    }
   },
   "outputs": [],
   "source": [
    "counter_training = 4000*2\n",
    "print(counter_training)\n",
    "counter_validation = 496*2\n",
    "print(counter_validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:57:03.768938Z",
     "iopub.status.busy": "2021-06-07T05:57:03.768477Z",
     "iopub.status.idle": "2021-06-07T05:57:43.790426Z",
     "shell.execute_reply": "2021-06-07T05:57:43.787117Z",
     "shell.execute_reply.started": "2021-06-07T05:57:03.768899Z"
    }
   },
   "outputs": [],
   "source": [
    "# training\n",
    "# with open('../input/20bnjester/training-targets.pkl', 'rb') as file:\n",
    "#     training_targets = pickle.load(file)\n",
    "\n",
    "# with open('../input/20bnjester/new-frames.pkl', 'rb') as file:\n",
    "#     new_frames = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:57:43.795783Z",
     "iopub.status.busy": "2021-06-07T05:57:43.79491Z",
     "iopub.status.idle": "2021-06-07T05:57:49.500554Z",
     "shell.execute_reply": "2021-06-07T05:57:49.499363Z",
     "shell.execute_reply.started": "2021-06-07T05:57:43.795702Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# validation\n",
    "# with open('../input/20bnjester/cv-targets.pkl', 'rb') as file:\n",
    "#     cv_targets = pickle.load(file)\n",
    "\n",
    "# with open('../input/20bnjester/cv-new-frames.pkl', 'rb') as file:\n",
    "#     new_frames_cv = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:57:49.503332Z",
     "iopub.status.busy": "2021-06-07T05:57:49.502878Z",
     "iopub.status.idle": "2021-06-07T05:58:07.325423Z",
     "shell.execute_reply": "2021-06-07T05:58:07.323943Z",
     "shell.execute_reply.started": "2021-06-07T05:57:49.503286Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert training data to np float32\n",
    "training_data = np.array(new_frames[0:counter_training], dtype=np.float32)\n",
    "training_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:07.328217Z",
     "iopub.status.busy": "2021-06-07T05:58:07.327697Z",
     "iopub.status.idle": "2021-06-07T05:58:08.042916Z",
     "shell.execute_reply": "2021-06-07T05:58:08.041426Z",
     "shell.execute_reply.started": "2021-06-07T05:58:07.328165Z"
    }
   },
   "outputs": [],
   "source": [
    "# convert validation data to np float32\n",
    "cv_data = np.array(new_frames_cv[0:counter_validation], dtype=np.float32)\n",
    "cv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:08.0462Z",
     "iopub.status.busy": "2021-06-07T05:58:08.045188Z",
     "iopub.status.idle": "2021-06-07T05:58:08.055887Z",
     "shell.execute_reply": "2021-06-07T05:58:08.054017Z",
     "shell.execute_reply.started": "2021-06-07T05:58:08.046122Z"
    }
   },
   "outputs": [],
   "source": [
    "# To check training length\n",
    "print(\"Training new frames:\", len(training_data))\n",
    "\n",
    "# To check validation length\n",
    "print(\"Validation new frames:\", len(cv_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:08.059722Z",
     "iopub.status.busy": "2021-06-07T05:58:08.058384Z",
     "iopub.status.idle": "2021-06-07T05:58:08.333519Z",
     "shell.execute_reply": "2021-06-07T05:58:08.332124Z",
     "shell.execute_reply.started": "2021-06-07T05:58:08.059651Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:08.335431Z",
     "iopub.status.busy": "2021-06-07T05:58:08.335075Z",
     "iopub.status.idle": "2021-06-07T05:58:09.515579Z",
     "shell.execute_reply": "2021-06-07T05:58:09.514285Z",
     "shell.execute_reply.started": "2021-06-07T05:58:08.335393Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "def normalization(data):\n",
    "    print('old mean', data.mean())\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    scaled_images  = scaler.fit_transform(data.reshape(-1, 15*64*64))\n",
    "    print('new mean', scaled_images.mean())\n",
    "    \n",
    "    scaled_images  = scaled_images.reshape(-1, 15, 64, 64, 1)    \n",
    "    print(scaled_images.shape)\n",
    "    \n",
    "    return scaled_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:09.520161Z",
     "iopub.status.busy": "2021-06-07T05:58:09.519567Z",
     "iopub.status.idle": "2021-06-07T05:58:20.045866Z",
     "shell.execute_reply": "2021-06-07T05:58:20.04456Z",
     "shell.execute_reply.started": "2021-06-07T05:58:09.520103Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalisation: training\n",
    "scaled_images = normalization(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:20.048423Z",
     "iopub.status.busy": "2021-06-07T05:58:20.048091Z",
     "iopub.status.idle": "2021-06-07T05:58:21.259881Z",
     "shell.execute_reply": "2021-06-07T05:58:21.258634Z",
     "shell.execute_reply.started": "2021-06-07T05:58:20.048389Z"
    }
   },
   "outputs": [],
   "source": [
    "# Normalisation: validation\n",
    "scaled_images_cv = normalization(cv_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:21.261719Z",
     "iopub.status.busy": "2021-06-07T05:58:21.261403Z",
     "iopub.status.idle": "2021-06-07T05:58:21.439841Z",
     "shell.execute_reply": "2021-06-07T05:58:21.43845Z",
     "shell.execute_reply.started": "2021-06-07T05:58:21.261685Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:21.441896Z",
     "iopub.status.busy": "2021-06-07T05:58:21.44155Z",
     "iopub.status.idle": "2021-06-07T05:58:28.069183Z",
     "shell.execute_reply": "2021-06-07T05:58:28.068142Z",
     "shell.execute_reply.started": "2021-06-07T05:58:21.44186Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:28.07158Z",
     "iopub.status.busy": "2021-06-07T05:58:28.070839Z",
     "iopub.status.idle": "2021-06-07T05:58:28.146624Z",
     "shell.execute_reply": "2021-06-07T05:58:28.1456Z",
     "shell.execute_reply.started": "2021-06-07T05:58:28.071527Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras import Model\n",
    "from keras.layers import Conv3D, MaxPool3D, ConvLSTM2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:28.148523Z",
     "iopub.status.busy": "2021-06-07T05:58:28.147949Z",
     "iopub.status.idle": "2021-06-07T05:58:28.160498Z",
     "shell.execute_reply": "2021-06-07T05:58:28.159141Z",
     "shell.execute_reply.started": "2021-06-07T05:58:28.148484Z"
    }
   },
   "outputs": [],
   "source": [
    "class Conv3DModel(Model):\n",
    "    def __init__(self):\n",
    "        super(Conv3DModel, self).__init__()\n",
    "#         with tpu_strategy.scope():\n",
    "        # Convolutions\n",
    "        self.conv1 = Conv3D(32, (3, 3, 3), activation='relu', name=\"conv1\", data_format='channels_last')\n",
    "        self.pool1 = MaxPool3D(pool_size=(2, 2, 2), data_format='channels_last')\n",
    "        self.conv2 = Conv3D(64, (3, 3, 3), activation='relu', name=\"conv1\", data_format='channels_last')\n",
    "        self.pool2 = MaxPool3D(pool_size=(2, 2,2), data_format='channels_last')\n",
    "\n",
    "        # LSTM & Flatten\n",
    "        self.convLSTM = ConvLSTM2D(40, (3, 3))\n",
    "        self.flatten = Flatten(name=\"flatten\")\n",
    "\n",
    "        # Dense layers\n",
    "        self.d1 = Dense(128, activation='relu', name=\"d1\")\n",
    "        self.out = Dense(8, activation='softmax', name=\"output\")\n",
    "\n",
    "    def call(self, x):\n",
    "#         with tpu_strategy.scope():\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.convLSTM(x)\n",
    "        #x = self.pool2(x)\n",
    "        #x = self.conv3(x)\n",
    "        #x = self.pool3(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.d1(x)\n",
    "        return self.out(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:28.163841Z",
     "iopub.status.busy": "2021-06-07T05:58:28.163241Z",
     "iopub.status.idle": "2021-06-07T05:58:28.243133Z",
     "shell.execute_reply": "2021-06-07T05:58:28.242086Z",
     "shell.execute_reply.started": "2021-06-07T05:58:28.163796Z"
    }
   },
   "outputs": [],
   "source": [
    "# with tpu_strategy.scope():\n",
    "model = Conv3DModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:28.245398Z",
     "iopub.status.busy": "2021-06-07T05:58:28.244773Z",
     "iopub.status.idle": "2021-06-07T05:58:32.146205Z",
     "shell.execute_reply": "2021-06-07T05:58:32.145071Z",
     "shell.execute_reply.started": "2021-06-07T05:58:28.24536Z"
    }
   },
   "outputs": [],
   "source": [
    "# use tensorflow dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((scaled_images, training_targets))\n",
    "cv_dataset = tf.data.Dataset.from_tensor_slices((scaled_images_cv, cv_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.148568Z",
     "iopub.status.busy": "2021-06-07T05:58:32.14785Z",
     "iopub.status.idle": "2021-06-07T05:58:32.477572Z",
     "shell.execute_reply": "2021-06-07T05:58:32.476546Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.148522Z"
    }
   },
   "outputs": [],
   "source": [
    "model(scaled_images[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.479849Z",
     "iopub.status.busy": "2021-06-07T05:58:32.479191Z",
     "iopub.status.idle": "2021-06-07T05:58:32.49275Z",
     "shell.execute_reply": "2021-06-07T05:58:32.491264Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.479806Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.494979Z",
     "iopub.status.busy": "2021-06-07T05:58:32.494565Z",
     "iopub.status.idle": "2021-06-07T05:58:32.778929Z",
     "shell.execute_reply": "2021-06-07T05:58:32.777756Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.494922Z"
    }
   },
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.781206Z",
     "iopub.status.busy": "2021-06-07T05:58:32.780754Z",
     "iopub.status.idle": "2021-06-07T05:58:32.79403Z",
     "shell.execute_reply": "2021-06-07T05:58:32.792561Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.781151Z"
    }
   },
   "outputs": [],
   "source": [
    "from keras.losses import SparseCategoricalCrossentropy\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import Mean, SparseCategoricalAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.796684Z",
     "iopub.status.busy": "2021-06-07T05:58:32.796123Z",
     "iopub.status.idle": "2021-06-07T05:58:32.809456Z",
     "shell.execute_reply": "2021-06-07T05:58:32.807893Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.79664Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_fn = SparseCategoricalCrossentropy()\n",
    "optimizer = Adam()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.812016Z",
     "iopub.status.busy": "2021-06-07T05:58:32.811425Z",
     "iopub.status.idle": "2021-06-07T05:58:32.854706Z",
     "shell.execute_reply": "2021-06-07T05:58:32.853505Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.811864Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loss\n",
    "train_loss = Mean(name='train_loss')\n",
    "valid_loss = Mean(name='valid_loss')\n",
    "# Accuracy\n",
    "train_accuracy = SparseCategoricalAccuracy(name='train_accuracy')\n",
    "valid_accuracy = SparseCategoricalAccuracy(name='valid_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.856713Z",
     "iopub.status.busy": "2021-06-07T05:58:32.85636Z",
     "iopub.status.idle": "2021-06-07T05:58:32.86648Z",
     "shell.execute_reply": "2021-06-07T05:58:32.86518Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.856674Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # Make a prediction on all the batch\n",
    "        predictions = model(image)\n",
    "        # Get the error/loss on these predictions\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    # Compute the gradient which respect to the loss\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    # Change the weights of the model\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "    # The metrics are accumulate over time. You don't need to average it yourself.\n",
    "    train_loss(loss)\n",
    "    train_accuracy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.870748Z",
     "iopub.status.busy": "2021-06-07T05:58:32.870309Z",
     "iopub.status.idle": "2021-06-07T05:58:32.87774Z",
     "shell.execute_reply": "2021-06-07T05:58:32.876379Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.870701Z"
    }
   },
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def valid_step(image, targets):\n",
    "    predictions = model(image)\n",
    "    t_loss = loss_fn(targets, predictions)\n",
    "    # Set the metrics for the test\n",
    "    valid_loss(t_loss)\n",
    "    valid_accuracy(targets, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.880025Z",
     "iopub.status.busy": "2021-06-07T05:58:32.879565Z",
     "iopub.status.idle": "2021-06-07T05:58:32.89966Z",
     "shell.execute_reply": "2021-06-07T05:58:32.898261Z",
     "shell.execute_reply.started": "2021-06-07T05:58:32.879984Z"
    }
   },
   "outputs": [],
   "source": [
    "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, model=model)\n",
    "manager = tf.train.CheckpointManager(ckpt, 'training_checkpoints/tf_ckpts', max_to_keep=10)\n",
    "ckpt.restore(manager.latest_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-06-07T05:58:32.901648Z",
     "iopub.status.busy": "2021-06-07T05:58:32.901307Z"
    }
   },
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "batch_size = 32\n",
    "b = 0\n",
    "training_acc = []\n",
    "validation_acc = []\n",
    "for epoch in range(epoch):\n",
    "    # Training set\n",
    "    for images_batch, targets_batch in train_dataset.batch(batch_size):\n",
    "        train_step(images_batch, targets_batch)\n",
    "        template = '\\r Batch {}/{}, Loss: {}, Accuracy: {}'\n",
    "        print(template.format(\n",
    "            b, len(training_targets), train_loss.result(), \n",
    "            train_accuracy.result()*100\n",
    "        ), end=\"\")\n",
    "        b += batch_size\n",
    "    # Validation set\n",
    "    for images_batch, targets_batch in cv_dataset.batch(batch_size):\n",
    "        valid_step(images_batch, targets_batch)\n",
    "\n",
    "    template = '\\nEpoch {}, Valid Loss: {}, Valid Accuracy: {}'\n",
    "    print(template.format(\n",
    "        epoch+1,\n",
    "        valid_loss.result(), \n",
    "        valid_accuracy.result()*100)\n",
    "    )\n",
    "    training_acc.append(float(train_accuracy.result()*100))\n",
    "    validation_acc.append(float(valid_accuracy.result()*100))\n",
    "    ckpt.step.assign_add(1)\n",
    "    save_path = manager.save()\n",
    "    print(\"Saved checkpoint for step {}: {}\".format(int(ckpt.step), save_path))\n",
    "    valid_loss.reset_states()\n",
    "    valid_accuracy.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    train_loss.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(manager.checkpoints)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model for use in the application\n",
    "model.save_weights('weights/path_to_my_weights', save_format='tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plote Accuracy / epoch\n",
    "plt.plot([1,2,3,4,5,6,7,8,9,10],training_acc, '-' )\n",
    "plt.plot([1,2,3,4,5,6,7,8,9,10],validation_acc, '-' )\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import plot_model"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4eaf1be304415beee96765ae99c3f893cc8312c7f1196698e6029668e9aeb3e5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
